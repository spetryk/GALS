{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lisabdunlap/vl-attention\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torchray.attribution.grad_cam import grad_cam as tr_gradcam\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import PIL\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "if os.getcwd().split(os.sep)[-1] == 'notebooks':\n",
    "    os.chdir('..')\n",
    "print(os.getcwd())\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "\n",
    "import clip\n",
    "# from CLIP.clip import clip\n",
    "\n",
    "\n",
    "from utils.rise import RISE\n",
    "from models.resnet import resnet18, resnet50\n",
    "import utils.general_utils as gu\n",
    "import utils.attention_utils as au\n",
    "from datasets import normalizations\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengths: 101000 to 1250\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6'\n",
    "\n",
    "\n",
    "cfg_file = 'configs/waterbirds_generic.yaml'\n",
    "\n",
    "DATASET = 'food_meat'\n",
    "\n",
    "if DATASET == 'waterbirds':\n",
    "    from datasets.waterbirds import Waterbirds as Dataset\n",
    "    cfg_file = 'configs/waterbirds_generic.yaml'\n",
    "    cfg      = OmegaConf.load(cfg_file)\n",
    "    #cfg.DATA.WATERBIRDS_DIR = 'waterbird_1.0_forest2water2'\n",
    "    #cfg.DATA.CONFOUNDING_FACTOR = 1.0\n",
    "elif DATASET == 'flowers':\n",
    "    from datasets.flowers import Flowers as Dataset\n",
    "    cfg_file = 'configs/flowers_generic.yaml'\n",
    "    cfg      = OmegaConf.load(cfg_file)\n",
    "    cfg.DATA.BIAS_TYPE = 'BigBoxTextFlowers'\n",
    "elif DATASET == 'food':\n",
    "    from datasets.food import Food as Dataset\n",
    "    cfg_file = 'configs/food_generic.yaml'\n",
    "    cfg      = OmegaConf.load(cfg_file)\n",
    "    cfg.DATA.CLASSES = ['steak', 'prime_rib']\n",
    "elif DATASET == 'food_mix':\n",
    "    from datasets.food import Food as Dataset\n",
    "    cfg_file = 'configs/food_generic.yaml'\n",
    "    cfg      = OmegaConf.load(cfg_file)\n",
    "    cfg.DATA.CLASSES = ['steak', 'prime_rib']\n",
    "    cfg.DATA.SUBDIR = 'food-101-subset-mix'\n",
    "elif DATASET == 'food_full':\n",
    "    from datasets.food import Food as Dataset\n",
    "    cfg_file = 'configs/food_generic.yaml'\n",
    "    cfg      = OmegaConf.load(cfg_file)\n",
    "    cfg.DATA.CLASSES = None\n",
    "    cfg.DATA.SUBDIR = 'food-101'\n",
    "elif DATASET == 'food_meat':\n",
    "    from datasets.food import FoodSubset as Dataset\n",
    "    cfg_file = 'configs/food_generic.yaml'\n",
    "    cfg      = OmegaConf.load(cfg_file)\n",
    "    cfg.DATA.CLASSES = None\n",
    "    cfg.DATA.SUBDIR = 'food-101'\n",
    "    cfg.DATA.CLASSES = ['prime_rib', 'pork_chop', 'steak', 'baby_back_ribs', 'filet_mignon']\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "base_cfg  = OmegaConf.load('configs/base.yaml')\n",
    "\n",
    "cfg = OmegaConf.merge(base_cfg, cfg)\n",
    "    \n",
    " \n",
    "mean, std = normalizations.normalizations[cfg.DATA.NORMALIZATION]['mean'], normalizations.normalizations[cfg.DATA.NORMALIZATION]['std']\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "dataset = Dataset(root='/shared/lisabdunlap/data',\n",
    "                  cfg=cfg,\n",
    "                  transform=transform,\n",
    "                  split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess = clip.load(\"RN50\", device=device, jit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a photo of apple pie', 'a photo of baby back ribs', 'a photo of baklava', 'a photo of beef carpaccio', 'a photo of beef tartare', 'a photo of beet salad', 'a photo of beignets', 'a photo of bibimbap', 'a photo of bread pudding', 'a photo of breakfast burrito', 'a photo of bruschetta', 'a photo of caesar salad', 'a photo of cannoli', 'a photo of caprese salad', 'a photo of carrot cake', 'a photo of ceviche', 'a photo of cheese plate', 'a photo of cheesecake', 'a photo of chicken curry', 'a photo of chicken quesadilla', 'a photo of chicken wings', 'a photo of chocolate cake', 'a photo of chocolate mousse', 'a photo of churros', 'a photo of clam chowder', 'a photo of club sandwich', 'a photo of crab cakes', 'a photo of creme brulee', 'a photo of croque madame', 'a photo of cup cakes', 'a photo of deviled eggs', 'a photo of donuts', 'a photo of dumplings', 'a photo of edamame', 'a photo of eggs benedict', 'a photo of escargots', 'a photo of falafel', 'a photo of filet mignon', 'a photo of fish and chips', 'a photo of foie gras', 'a photo of french fries', 'a photo of french onion soup', 'a photo of french toast', 'a photo of fried calamari', 'a photo of fried rice', 'a photo of frozen yogurt', 'a photo of garlic bread', 'a photo of gnocchi', 'a photo of greek salad', 'a photo of grilled cheese sandwich', 'a photo of grilled salmon', 'a photo of guacamole', 'a photo of gyoza', 'a photo of hamburger', 'a photo of hot and sour soup', 'a photo of hot dog', 'a photo of huevos rancheros', 'a photo of hummus', 'a photo of ice cream', 'a photo of lasagna', 'a photo of lobster bisque', 'a photo of lobster roll sandwich', 'a photo of macaroni and cheese', 'a photo of macarons', 'a photo of miso soup', 'a photo of mussels', 'a photo of nachos', 'a photo of omelette', 'a photo of onion rings', 'a photo of oysters', 'a photo of pad thai', 'a photo of paella', 'a photo of pancakes', 'a photo of panna cotta', 'a photo of peking duck', 'a photo of pho', 'a photo of pizza', 'a photo of pork chop', 'a photo of poutine', 'a photo of prime rib', 'a photo of pulled pork sandwich', 'a photo of ramen', 'a photo of ravioli', 'a photo of red velvet cake', 'a photo of risotto', 'a photo of samosa', 'a photo of sashimi', 'a photo of scallops', 'a photo of seaweed salad', 'a photo of shrimp and grits', 'a photo of spaghetti bolognese', 'a photo of spaghetti carbonara', 'a photo of spring rolls', 'a photo of steak', 'a photo of strawberry shortcake', 'a photo of sushi', 'a photo of tacos', 'a photo of takoyaki', 'a photo of tiramisu', 'a photo of tuna tartare', 'a photo of waffles']\n"
     ]
    }
   ],
   "source": [
    "preprocess_no_crop = []\n",
    "for t in preprocess.transforms:\n",
    "    if type(t) == torchvision.transforms.transforms.Resize:\n",
    "        preprocess_no_crop.append(transforms.Resize((224,224), interpolation=PIL.Image.BICUBIC))\n",
    "    else:\n",
    "        if type(t) != torchvision.transforms.transforms.CenterCrop:\n",
    "            preprocess_no_crop.append(t)\n",
    "preprocess = transforms.Compose(preprocess_no_crop)\n",
    "\n",
    "# prompts = ['a photo of prime rib', 'a photo of steak']\n",
    "prompts = [f\"a photo of {c.replace('_', ' ')}\" for c in dataset.classes]\n",
    "print(prompts)\n",
    "tokenized_text = clip.tokenize(prompts).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [01:02<00:00, 20.09it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    batch = dataset.__getitem__(i)\n",
    "    path = batch['image_path']\n",
    "    label = int(batch['label'])\n",
    "    \n",
    "    image = preprocess(Image.open(path)).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image)\n",
    "\n",
    "        logits_per_image, logits_per_text = model(image, tokenized_text)\n",
    "        probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "        \n",
    "        pred = np.argmax(probs)\n",
    "\n",
    "        preds.append(pred)\n",
    "        labels.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7485940594059406"
      ]
     },
     "execution_count": 16,
       "0.6984"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(preds) == np.array(labels)).sum() / len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.990e-01, 8.297e-04]], dtype=float16)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
