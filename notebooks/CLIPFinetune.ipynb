{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ebb5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getcwd().split(os.sep)[-1] == 'notebooks':\n",
    "    os.chdir('..')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2792026",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "#import CLIP.clip as clip\n",
    "import clip\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import PIL\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "\n",
    "import torchvision \n",
    "\n",
    "from utils import general_utils as gu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a5406",
   "metadata": {},
   "outputs": [],
   "source": [
    "device    = \"cuda:2\"\n",
    "#clip_type = 'ViT-B/32'\n",
    "clip_type = 'RN50'\n",
    "\n",
    "model, preprocess = clip.load(clip_type, device, jit=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617baa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#cfg_file  = 'configs/waterbirds_generic.yaml'\n",
    "#cfg_file  = 'configs/coco_generic.yaml'\n",
    "#cfg_file  = 'configs/coco_device.yaml'\n",
    "#cfg_file  = 'configs/planes.yaml'\n",
    "cfg_file  = 'configs/food_subset_generic.yaml'\n",
    "base_cfg  = OmegaConf.load('configs/base.yaml')\n",
    "cfg       = OmegaConf.load(cfg_file)\n",
    "args = OmegaConf.merge(base_cfg, cfg)\n",
    "\n",
    "\n",
    "if args.DATA.DATASET == 'waterbirds':\n",
    "    from datasets.waterbirds import Waterbirds as Dataset\n",
    "    cfg.DATA.WATERBIRDS_DIR = 'waterbird_1.0_forest2water2'\n",
    "    cfg.DATA.CONFOUNDING_FACTOR = 1.0\n",
    "elif args.DATA.DATASET == 'coco_gender':\n",
    "    from datasets.coco import COCOGender as Dataset\n",
    "elif args.DATA.DATASET == 'coco_device':\n",
    "    from datasets.coco_device import COCODevice as Dataset\n",
    "elif args.DATA.DATASET == 'planes':\n",
    "    from datasets.planes import Planes as Dataset\n",
    "    args.DATA.BIAS_TYPE = 'bias_A'\n",
    "elif args.DATA.DATASET == 'food':\n",
    "    from datasets.food import Food as Dataset\n",
    "elif args.DATA.DATASET == 'food_subset':\n",
    "    from datasets.food import FoodSubset as Dataset\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "    \n",
    " \n",
    "\n",
    "transform = None\n",
    "train_dataset = Dataset(root='./data',\n",
    "                  cfg=args,\n",
    "                  transform=transform,\n",
    "                  split='train')\n",
    "val_dataset = Dataset(root='./data',\n",
    "                  cfg=args,\n",
    "                  transform=transform,\n",
    "                  split='val')\n",
    "test_dataset = Dataset(root='./data',\n",
    "                  cfg=args,\n",
    "                  transform=transform,\n",
    "                  split='test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0032fd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=args.DATA.BATCH_SIZE,\n",
    "                                               num_workers=args.DATA.NUM_WORKERS,\n",
    "                                               shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                             batch_size=args.DATA.BATCH_SIZE,\n",
    "                                             num_workers=args.DATA.NUM_WORKERS,\n",
    "                                             shuffle=False)\n",
    "\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                             batch_size=1,\n",
    "                                             num_workers=args.DATA.NUM_WORKERS,\n",
    "                                             shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c80c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_features(image_filenames, preprocess):\n",
    "    all_features = []\n",
    "    \n",
    "    #with torch.no_grad():\n",
    "    torch.set_grad_enabled(False)\n",
    "    for image in tqdm(image_filenames, total=len(image_filenames)):\n",
    "        image = preprocess(Image.open(image)).unsqueeze(0).to(device)\n",
    "        features = model.encode_image(image)\n",
    "        all_features.append(features)\n",
    "\n",
    "    torch.set_grad_enabled(True)\n",
    "    return torch.cat(all_features)#.cpu().numpy()\n",
    "\n",
    "\n",
    "def group_accuracy(group_labels, class_labels, predictions, num_groups):\n",
    "    accs = []\n",
    "    for group in range(num_groups):\n",
    "        indices = np.where(group_labels == group)[0]\n",
    "        #print('Num samples of group {}: {}'.format(group, len(indices)))\n",
    "        group_preds = predictions[indices]\n",
    "        group_gt = class_labels[indices]\n",
    "        acc = np.mean((group_preds == group_gt).astype(float)) * 100.\n",
    "        accs.append(acc)\n",
    "    group_accs = np.array(accs)\n",
    "    gs = [np.round(g,2) for g in group_accs]\n",
    "    print('Group accs: {}'.format(gs))\n",
    "    return group_accs\n",
    "\n",
    "def class_accuracy(labels, predictions, num_classes):\n",
    "    accs = []\n",
    "    for cls in range(num_classes):\n",
    "        indices = np.where(labels == cls)[0]\n",
    "        class_preds = predictions[indices]\n",
    "        class_gt = labels[indices]\n",
    "        acc = np.mean((class_gt == class_preds).astype(float)) * 100.\n",
    "        accs.append(acc)\n",
    "    accs = [np.round(a, 2) for a in accs]\n",
    "    print('Class accs: {}'.format(accs))\n",
    "    print('Mean class acc: {}'.format(np.array(accs).mean()))\n",
    "    return np.array(accs)\n",
    "        \n",
    "\n",
    "def predict_zero_shot(model, all_image_features, text_features):\n",
    "    torch.set_grad_enabled(False)\n",
    "    preds = []\n",
    "    for i in tqdm(range(all_image_features.shape[0])):\n",
    "        image_features = all_image_features[i]\n",
    "\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "        pred = np.argmax(probs.cpu().numpy())\n",
    "        preds.append(pred)\n",
    "        \n",
    "    torch.set_grad_enabled(True)\n",
    "    return np.array(preds)\n",
    "\n",
    "\n",
    "def evaluate(preds, labels, group_labels=None, num_groups=None, num_classes=2):\n",
    "    overall_acc = np.mean((preds == labels).astype(float))\n",
    "    print('Per instance acc: {}'.format(np.round(overall_acc*100., 2)))\n",
    "    class_accuracy(labels, preds, num_classes)\n",
    "\n",
    "    if group_labels is not None:\n",
    "        group_accuracy(group_labels, labels, preds, num_groups)\n",
    "\n",
    "\n",
    "def get_filenames_labels(dataset, dataset_type):\n",
    "    if dataset_type == 'waterbirds':\n",
    "        filenames = dataset.image_filenames\n",
    "        labels = dataset.labels_split\n",
    "    elif dataset_type == 'planes':\n",
    "        filenames = dataset.filenames\n",
    "        labels = dataset.labels\n",
    "    elif dataset_type == 'food_subset':\n",
    "        tuples = dataset.imgs\n",
    "        filenames = np.array([t[0] for t in tuples])\n",
    "        labels    = np.array([t[1] for t in tuples])\n",
    "    else:\n",
    "        filenames = dataset.filenames\n",
    "        labels = dataset.labels\n",
    "    return filenames, np.array(labels)\n",
    "\n",
    "\n",
    "def get_preprocess_no_crop(preprocess):\n",
    "    preprocess_no_crop = []\n",
    "    for t in preprocess.transforms:\n",
    "        if type(t) == torchvision.transforms.transforms.Resize:\n",
    "            preprocess_no_crop.append(transforms.Resize((224,224), interpolation=PIL.Image.BICUBIC))\n",
    "        else:\n",
    "            if type(t) != torchvision.transforms.transforms.CenterCrop:\n",
    "                preprocess_no_crop.append(t)\n",
    "    preprocess = transforms.Compose(preprocess_no_crop)\n",
    "    return preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eab786",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = get_preprocess_no_crop(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56dd798",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_filenames, train_labels = get_filenames_labels(train_dataset, args.DATA.DATASET)\n",
    "val_filenames, val_labels     = get_filenames_labels(val_dataset, args.DATA.DATASET)\n",
    "\n",
    "train_features = get_features(train_filenames, preprocess)\n",
    "val_features = get_features(val_filenames, preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94054b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.DATA.DATASET == 'waterbirds':\n",
    "    train_group_labels = train_dataset.group_labels_split\n",
    "    val_group_labels   = val_dataset.group_labels_split\n",
    "    test_group_labels  = test_dataset.group_labels_split\n",
    "    num_groups = 4\n",
    "    num_classes = 2\n",
    "elif args.DATA.DATASET == 'planes':\n",
    "    train_group_labels = train_dataset.groups\n",
    "    val_group_labels   = val_dataset.groups\n",
    "    test_group_labels  = test_dataset.groups\n",
    "    num_groups = 4\n",
    "    num_classes = 2\n",
    "elif args.DATA.DATASET == 'food_subset':\n",
    "    train_group_labels = None\n",
    "    val_group_labels   = None\n",
    "    test_group_labels  = None\n",
    "    num_groups = None\n",
    "    num_classes = 5\n",
    "else:\n",
    "    train_group_labels, val_group_labels, test_group_labels = None, None, None\n",
    "    num_groups = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6725cd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for C in [0.001, 0.1, 0.3, 0.5, 1, 5, 10, 100, 200, 500, 1000, 2000]:\n",
    "    print('*************************************************')\n",
    "    print('C: {}'.format(C))\n",
    "    classifier = LogisticRegression(random_state=0, C=C, max_iter=5000, verbose=1)\n",
    "    classifier.fit(train_features, train_labels)\n",
    "    print()\n",
    "    print('**** Train performance ****')\n",
    "    preds = classifier.predict(train_features)\n",
    "    evaluate(preds, train_labels, train_group_labels, num_groups=num_groups, num_classes=num_classes)\n",
    "\n",
    "    print('**** Val performance ***')\n",
    "    preds = classifier.predict(val_features)\n",
    "    evaluate(preds, val_labels, val_group_labels, num_groups=num_groups, num_classes=num_classes)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11509e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames, test_labels = get_filenames_labels(test_dataset, args.DATA.DATASET)\n",
    "test_features = get_features(test_filenames, preprocess)\n",
    "test_features = test_features.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3ea83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 0.3\n",
    "classifier = LogisticRegression(random_state=0, C=C, max_iter=5000, verbose=1)\n",
    "classifier.fit(train_features, train_labels)\n",
    "\n",
    "print('**** Test performance ***')\n",
    "preds = classifier.predict(test_features)\n",
    "evaluate(preds, test_labels, test_group_labels, num_groups=num_groups, num_classes=num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eb43fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
